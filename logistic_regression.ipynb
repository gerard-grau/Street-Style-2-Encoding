{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features_and_labels(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    features = dataframe.iloc[:, :-11]  # All columns except the last eleven\n",
    "    labels = dataframe.iloc[:, -11:]    # The last eleven columns\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load embeddings data\n",
    "embeddings_file = \"image_embeddings.pt\"\n",
    "\n",
    "embeddings_dict = torch.load(embeddings_file)\n",
    "\n",
    "products = pd.read_csv('data/product_with_attributes.csv')\n",
    "embeddings = [embeddings_dict[filename] for filename in products['des_filename']]\n",
    "\n",
    "# embeddings = [embedding.numpy() for embedding in embeddings]\n",
    "\n",
    "\n",
    "\n",
    "features, labels = split_features_and_labels(products)\n",
    "\n",
    "# Convert the list of embeddings to a NumPy array\n",
    "embeddings_array = np.array(embeddings)\n",
    "\n",
    "# Add each dimension as a separate feature\n",
    "for i in range(512):\n",
    "    features[f'embedding_dim_{i}'] = embeddings_array[:, i]\n",
    "# products = pd.concat([products, embedding_columns], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Given a fashion clip embedding\n",
    "# input_embedding = np.array([...])  # Replace with the actual embedding\n",
    "# embeddings_file_test = \"image_embeddings.pt\"\n",
    "# embeddings_dict_test = torch.load(embeddings_file)\n",
    "# mbeddings = [embeddings_dict[filename] for filename in products['des_filename']]\n",
    "\n",
    "encoded_labels = labels.apply(lambda x: pd.factorize(x)[0])\n",
    "unique_values = {col: pd.factorize(labels[col])[1] for col in labels.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>silhouette_type</th>\n",
       "      <th>neck_lapel_type</th>\n",
       "      <th>woven_structure</th>\n",
       "      <th>knit_structure</th>\n",
       "      <th>heel_shape_type</th>\n",
       "      <th>length_type</th>\n",
       "      <th>sleeve_length_type</th>\n",
       "      <th>toecap_type</th>\n",
       "      <th>waist_type</th>\n",
       "      <th>closure_placement</th>\n",
       "      <th>cane_height_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61479</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61480</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61481</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61482</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61483</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61484 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       silhouette_type  neck_lapel_type  woven_structure  knit_structure  \\\n",
       "0                    0                0                0               0   \n",
       "1                    1                1                1               1   \n",
       "2                    0                0                1               1   \n",
       "3                    2                2                2               1   \n",
       "4                    3                0                1               1   \n",
       "...                ...              ...              ...             ...   \n",
       "61479                0                4                1               1   \n",
       "61480                0                0                1               1   \n",
       "61481               16                2                0               1   \n",
       "61482                0                3                1               1   \n",
       "61483                0               11                3               1   \n",
       "\n",
       "       heel_shape_type  length_type  sleeve_length_type  toecap_type  \\\n",
       "0                    0            0                   0            0   \n",
       "1                    0            1                   1            0   \n",
       "2                    0            0                   1            0   \n",
       "3                    0            1                   2            0   \n",
       "4                    0            0                   0            0   \n",
       "...                ...          ...                 ...          ...   \n",
       "61479                0            0                   1            0   \n",
       "61480                0            0                   3            0   \n",
       "61481                0            2                   2            0   \n",
       "61482                0            5                   5            0   \n",
       "61483                0            7                   0            0   \n",
       "\n",
       "       waist_type  closure_placement  cane_height_type  \n",
       "0               0                  0                 0  \n",
       "1               0                  1                 0  \n",
       "2               0                  2                 0  \n",
       "3               1                  2                 0  \n",
       "4               0                  3                 0  \n",
       "...           ...                ...               ...  \n",
       "61479           0                  2                 0  \n",
       "61480           0                  2                 0  \n",
       "61481           0                  2                 0  \n",
       "61482           0                  5                 0  \n",
       "61483           0                  5                 0  \n",
       "\n",
       "[61484 rows x 11 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'silhouette_type': Index(['Recto', 'Evase', 'Skinny', 'Regular', 'Relaxed', 'INVALID', 'Jogger',\n",
       "        'Oversize', 'Slim', 'Palazzo', 'Paperbag', 'Acampanado/Flare',\n",
       "        'Push Up', 'Acampanado/Bootcut', 'Cargo', 'Tapered', 'Fino', 'Culotte',\n",
       "        'Slouchy', '5 Bolsillos', 'Mom', 'Wide leg', 'LÃ¡piz', 'Boyfriend',\n",
       "        'Ancho', 'Chino', 'Superslim', 'Loose', 'Parachute', 'Halter',\n",
       "        'Modern slim', 'Bandeau', 'Sarouel', 'Carrot'],\n",
       "       dtype='object'),\n",
       " 'neck_lapel_type': Index(['Redondo', 'Caja', 'INVALID', 'Camisero', 'Pico', 'Peak Lapel',\n",
       "        'Alto/Envolvente', 'Chimenea', 'Polo', 'Halter', 'Shawl', 'Capucha',\n",
       "        'Escotado', 'Mao', 'Off Shoulder', 'Solapa', 'Cruzado', 'Panadero',\n",
       "        'Regular', 'Drapeado', 'Barca', 'Perkins', 'Hawaiano/Bowling',\n",
       "        'Palabra Honor', 'Cisne', 'Button Down', 'Cutaway', 'AsimÃ©trico',\n",
       "        'Waterfall', 'Babydoll/Peter Pan', 'Espalda Abierta', 'Smoking',\n",
       "        'Kimono', 'Sin solapa'],\n",
       "       dtype='object'),\n",
       " 'woven_structure': Index(['INVALID', 'Ligero', 'Medio', 'Pesado', 'ElÃ¡stico'], dtype='object'),\n",
       " 'knit_structure': Index(['Punto Fino', 'INVALID', 'Punto Grueso', 'Punto medio', 'Punto grueso',\n",
       "        'Punto Medio', 'Punto fino', 'Hecho a mano', 'UNKNOWN'],\n",
       "       dtype='object'),\n",
       " 'heel_shape_type': Index(['INVALID', 'Plano', 'Bloque', 'Rectangular', 'Trompeta',\n",
       "        'Plataforma plana', 'Plataforma', 'De aguja', 'Embudo',\n",
       "        'Plataforma en la parte delantera', 'Kitten', 'CuÃ±a'],\n",
       "       dtype='object'),\n",
       " 'length_type': Index(['Standard', 'Largo', 'INVALID', 'Corto', 'Midi', 'Crop', 'Mini/Micro',\n",
       "        'Medio', 'Maxi', 'Tres Cuartos', 'Capri', 'Tobillero', 'AsimÃ©trico'],\n",
       "       dtype='object'),\n",
       " 'sleeve_length_type': Index(['Larga', 'Corta', 'INVALID', 'Sin Manga', 'Tirante Fino',\n",
       "        'Tres Cuartos', 'Tirante Ancho'],\n",
       "       dtype='object'),\n",
       " 'toecap_type': Index(['INVALID', 'Redonda', 'Cuadrada', 'Abierta', 'Con punta'], dtype='object'),\n",
       " 'waist_type': Index(['INVALID', 'High Waist', 'Ajustable/Goma', 'Regular Waist',\n",
       "        'Low Waist'],\n",
       "       dtype='object'),\n",
       " 'closure_placement': Index(['Cuello', 'Cierre Trasero', 'INVALID', 'Sin cierre', 'Lateral',\n",
       "        'Cierre Delantero', 'Cierre Hombro'],\n",
       "       dtype='object'),\n",
       " 'cane_height_type': Index(['INVALID', 'CuÃ±a abotinada', 'Bloque', 'CuÃ±a', 'Alta', 'Baja', 'Media'], dtype='object')}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>des_sex</th>\n",
       "      <th>des_age</th>\n",
       "      <th>des_line</th>\n",
       "      <th>des_fabric</th>\n",
       "      <th>des_product_category</th>\n",
       "      <th>des_product_aggregated_family</th>\n",
       "      <th>des_product_family</th>\n",
       "      <th>des_product_type</th>\n",
       "      <th>des_filename</th>\n",
       "      <th>des_color</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_dim_502</th>\n",
       "      <th>embedding_dim_503</th>\n",
       "      <th>embedding_dim_504</th>\n",
       "      <th>embedding_dim_505</th>\n",
       "      <th>embedding_dim_506</th>\n",
       "      <th>embedding_dim_507</th>\n",
       "      <th>embedding_dim_508</th>\n",
       "      <th>embedding_dim_509</th>\n",
       "      <th>embedding_dim_510</th>\n",
       "      <th>embedding_dim_511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Female</td>\n",
       "      <td>Kids</td>\n",
       "      <td>KIDS</td>\n",
       "      <td>TRICOT</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Sweaters and Cardigans</td>\n",
       "      <td>Sweater</td>\n",
       "      <td>Sweater</td>\n",
       "      <td>83_1124642_17074019-82_B.jpg</td>\n",
       "      <td>ROSA LIGHT</td>\n",
       "      <td>...</td>\n",
       "      <td>0.252419</td>\n",
       "      <td>-0.853426</td>\n",
       "      <td>-0.126018</td>\n",
       "      <td>-0.65395</td>\n",
       "      <td>0.638628</td>\n",
       "      <td>0.435513</td>\n",
       "      <td>0.365749</td>\n",
       "      <td>0.165159</td>\n",
       "      <td>0.394995</td>\n",
       "      <td>0.221404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 522 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  des_sex des_age des_line des_fabric des_product_category  \\\n",
       "0  Female    Kids     KIDS     TRICOT                 Tops   \n",
       "\n",
       "  des_product_aggregated_family des_product_family des_product_type  \\\n",
       "0        Sweaters and Cardigans            Sweater          Sweater   \n",
       "\n",
       "                   des_filename   des_color  ...  embedding_dim_502  \\\n",
       "0  83_1124642_17074019-82_B.jpg  ROSA LIGHT  ...           0.252419   \n",
       "\n",
       "   embedding_dim_503  embedding_dim_504  embedding_dim_505  embedding_dim_506  \\\n",
       "0          -0.853426          -0.126018           -0.65395           0.638628   \n",
       "\n",
       "   embedding_dim_507  embedding_dim_508  embedding_dim_509  embedding_dim_510  \\\n",
       "0           0.435513           0.365749           0.165159           0.394995   \n",
       "\n",
       "   embedding_dim_511  \n",
       "0           0.221404  \n",
       "\n",
       "[1 rows x 522 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = features.drop('cod_modelo_color', axis=1)\n",
    "features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61484, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_arr = np.array(features)\n",
    " \n",
    "features_arr[:, -512:].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>silhouette_type</th>\n",
       "      <th>neck_lapel_type</th>\n",
       "      <th>woven_structure</th>\n",
       "      <th>knit_structure</th>\n",
       "      <th>heel_shape_type</th>\n",
       "      <th>length_type</th>\n",
       "      <th>sleeve_length_type</th>\n",
       "      <th>toecap_type</th>\n",
       "      <th>waist_type</th>\n",
       "      <th>closure_placement</th>\n",
       "      <th>cane_height_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61479</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61480</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61481</th>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61482</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61483</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61484 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       silhouette_type  neck_lapel_type  woven_structure  knit_structure  \\\n",
       "0                    0                0                0               0   \n",
       "1                    1                1                1               1   \n",
       "2                    0                0                1               1   \n",
       "3                    2                2                2               1   \n",
       "4                    3                0                1               1   \n",
       "...                ...              ...              ...             ...   \n",
       "61479                0                4                1               1   \n",
       "61480                0                0                1               1   \n",
       "61481               16                2                0               1   \n",
       "61482                0                3                1               1   \n",
       "61483                0               11                3               1   \n",
       "\n",
       "       heel_shape_type  length_type  sleeve_length_type  toecap_type  \\\n",
       "0                    0            0                   0            0   \n",
       "1                    0            1                   1            0   \n",
       "2                    0            0                   1            0   \n",
       "3                    0            1                   2            0   \n",
       "4                    0            0                   0            0   \n",
       "...                ...          ...                 ...          ...   \n",
       "61479                0            0                   1            0   \n",
       "61480                0            0                   3            0   \n",
       "61481                0            2                   2            0   \n",
       "61482                0            5                   5            0   \n",
       "61483                0            7                   0            0   \n",
       "\n",
       "       waist_type  closure_placement  cane_height_type  \n",
       "0               0                  0                 0  \n",
       "1               0                  1                 0  \n",
       "2               0                  2                 0  \n",
       "3               1                  2                 0  \n",
       "4               0                  3                 0  \n",
       "...           ...                ...               ...  \n",
       "61479           0                  2                 0  \n",
       "61480           0                  2                 0  \n",
       "61481           0                  2                 0  \n",
       "61482           0                  5                 0  \n",
       "61483           0                  5                 0  \n",
       "\n",
       "[61484 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features_arr[:, -512:], encoded_labels, test_size=0.9, random_state=42)\n",
    "# X_train = features_arr[:, -512:]\n",
    "# y_train = encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6148, 512)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    # Use XGBoost as an example\n",
    "    clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1)\n",
    "    # clf = XGBClassifier(\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric='mlogloss',\n",
    "    #     n_jobs=-1,\n",
    "    #     max_depth=8,\n",
    "    #     learning_rate=0.1,\n",
    "    #     n_estimators=200,\n",
    "    #     # subsample=0.8,\n",
    "    #     # colsample_bytree=0.8,\n",
    "    #     gamma=0.1,\n",
    "    #     min_child_weight=5\n",
    "    # )\n",
    "    # clf = lgb.LGBMClassifier(\n",
    "    #     n_estimators=200,\n",
    "    #     learning_rate=0.1,\n",
    "    #     max_depth=8,\n",
    "    #     subsample=0.8,\n",
    "    #     colsample_bytree=0.8,\n",
    "    #     min_child_weight=5,\n",
    "    #     n_jobs=-1,\n",
    "    #     verbose=-1\n",
    "    # )\n",
    "    clf.fit(X_train, y_train[label])\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = f\"model_{label}_xgb_3.joblib\"\n",
    "    joblib.dump(clf, model_filename)\n",
    "    print(f\"Model for {label} saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29], got [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 24\n 25 26 27 28 29 30]\n\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31], got [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 33]\n\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30], got [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 30 33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 26\u001b[0m\n\u001b[1;32m     13\u001b[0m clf \u001b[38;5;241m=\u001b[39m XGBClassifier(use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     16\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mclf,\n\u001b[1;32m     17\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m best_clf \u001b[38;5;241m=\u001b[39m random_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     29\u001b[0m best_clf\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     30\u001b[0m     X_train, y_train[label],\n\u001b[1;32m     31\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[1;32m     32\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39m[(X_val, y_val[label])],\n\u001b[1;32m     33\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     34\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1960\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1958\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1959\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1960\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1963\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    994\u001b[0m     )\n\u001b[0;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 30 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29], got [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 24\n 25 26 27 28 29 30]\n\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 31], got [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30 33]\n\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/core.py\", line 726, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"/home/guimcc/anaconda3/envs/datascience/lib/python3.12/site-packages/xgboost/sklearn.py\", line 1491, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 29 30], got [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n 24 25 26 27 28 30 33]\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "for label in labels:\n",
    "    # Use XGBoost as an example\n",
    "    clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', n_jobs=-1)\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=clf,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=10,  # Limit iterations for speed\n",
    "        scoring='accuracy',\n",
    "        cv=cv,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    random_search.fit(X_train, y_train[label])\n",
    "    best_clf = random_search.best_estimator_\n",
    "    \n",
    "    best_clf.fit(\n",
    "        X_train, y_train[label],\n",
    "        early_stopping_rounds=10,\n",
    "        eval_set=[(X_val, y_val[label])],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    # clf = XGBClassifier(\n",
    "    #     use_label_encoder=False,\n",
    "    #     eval_metric='mlogloss',\n",
    "    #     n_jobs=-1,\n",
    "    #     max_depth=8,\n",
    "    #     learning_rate=0.1,\n",
    "    #     n_estimators=200,\n",
    "    #     # subsample=0.8,\n",
    "    #     # colsample_bytree=0.8,\n",
    "    #     gamma=0.1,\n",
    "    #     min_child_weight=5\n",
    "    # )\n",
    "    # clf = lgb.LGBMClassifier(\n",
    "    #     n_estimators=200,\n",
    "    #     learning_rate=0.1,\n",
    "    #     max_depth=8,\n",
    "    #     subsample=0.8,\n",
    "    #     colsample_bytree=0.8,\n",
    "    #     min_child_weight=5,\n",
    "    #     n_jobs=-1,\n",
    "    #     verbose=-1\n",
    "    # )\n",
    "    clf.fit(X_train, y_train[label])\n",
    "\n",
    "    # Save the model\n",
    "    model_filename = f\"model_{label}_xgb_4_optimized.joblib\"\n",
    "    joblib.dump(clf, model_filename)\n",
    "    print(f\"Model for {label} saved as {model_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lo_p = \"model_neck_lapel_type_xgb_2.joblib\"  # Replace with your actual file name\n",
    "model_lo = joblib.load(model_lo_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_lo.predict(X_test)\n",
    "yo = labels['neck_lapel_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12297,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test['neck_lapel_type'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6856956981377572"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test['neck_lapel_type'], y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for label in labels:\n",
    "    model_filename = f\"model_{label}_xgb_3.joblib\"\n",
    "    \n",
    "    models[label] = joblib.load(model_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for silhouette_type: 0.0\n",
      "Accuracy for neck_lapel_type: 0.0\n",
      "Accuracy for woven_structure: 0.0\n",
      "Accuracy for knit_structure: 0.0\n",
      "Accuracy for heel_shape_type: 0.0\n",
      "Accuracy for length_type: 0.0\n",
      "Accuracy for sleeve_length_type: 0.0\n",
      "Accuracy for toecap_type: 0.0\n",
      "Accuracy for waist_type: 0.0\n",
      "Accuracy for closure_placement: 0.0\n",
      "Accuracy for cane_height_type: 0.0\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    model = models[label]\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test[label], y_pred)\n",
    "    print(f\"Accuracy for {label}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/media/guimcc/Elements/datathon\"\n",
    "IMAGES_PATH = f\"{PATH}/archive/images/images/\"\n",
    "CSV_PATH = f\"{PATH}/archive/\"\n",
    "HEIGHT = 224\n",
    "WIDTH = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_200186/1468544703.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  embeddings_dict_test = torch.load(embeddings_file_test)\n"
     ]
    }
   ],
   "source": [
    "embeddings_file_test = \"image_embeddings_test.pt\"\n",
    "embeddings_dict_test = torch.load(embeddings_file_test)\n",
    "df_test = pd.read_csv(f\"{CSV_PATH}/test_data.csv\")\n",
    "embeddings_test = [embeddings_dict_test[filename] for filename in df_test['des_filename']]\n",
    "\n",
    "embeddings_test = np.array(embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "predictions['des_filename'] = df_test['des_filename']\n",
    "predictions['test_id'] = df_test['test_id']\n",
    "for label in labels:\n",
    "    model = models[label]\n",
    "    prediction = model.predict(embeddings_test)\n",
    "    predictions[label] = prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_back_to_original(predictions, unique_values):\n",
    "    # Iterate over each column that needs to be mapped\n",
    "    for column in unique_values.keys():\n",
    "        # Replace the encoded values with the original labels\n",
    "        predictions[column] = predictions[column].apply(lambda x: unique_values[column][x])\n",
    "    return predictions\n",
    "\n",
    "predictions_mapped = map_back_to_original(predictions, unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>des_filename</th>\n",
       "      <th>test_id</th>\n",
       "      <th>silhouette_type</th>\n",
       "      <th>neck_lapel_type</th>\n",
       "      <th>woven_structure</th>\n",
       "      <th>knit_structure</th>\n",
       "      <th>heel_shape_type</th>\n",
       "      <th>length_type</th>\n",
       "      <th>sleeve_length_type</th>\n",
       "      <th>toecap_type</th>\n",
       "      <th>waist_type</th>\n",
       "      <th>closure_placement</th>\n",
       "      <th>cane_height_type</th>\n",
       "      <th>attribute_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88_49711373_67080432-99_.jpg</td>\n",
       "      <td>88_49711373_cane_height_type</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Plano</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Redonda</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Alta</td>\n",
       "      <td>cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88_49718802_67030656-99_.jpg</td>\n",
       "      <td>88_49718802_cane_height_type</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Bloque</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Con punta</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88_49709572_67030418-01_B.jpg</td>\n",
       "      <td>88_49709572_cane_height_type</td>\n",
       "      <td>Recto</td>\n",
       "      <td>Redondo</td>\n",
       "      <td>Ligero</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Corta</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88_49722701_67066002-02_.jpg</td>\n",
       "      <td>88_49722701_cane_height_type</td>\n",
       "      <td>Evase</td>\n",
       "      <td>Redondo</td>\n",
       "      <td>Ligero</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Corto</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88_49724926_67056330-02_B.jpg</td>\n",
       "      <td>88_49724926_cane_height_type</td>\n",
       "      <td>Recto</td>\n",
       "      <td>Redondo</td>\n",
       "      <td>Ligero</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Corta</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Cierre Delantero</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>cane_height_type</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71814</th>\n",
       "      <td>88_49727540_67069223-56_.jpg</td>\n",
       "      <td>88_49727540_knit_structure</td>\n",
       "      <td>Slim</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Ligero</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Larga</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Cierre Delantero</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>knit_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71815</th>\n",
       "      <td>88_49733648_67017145-56_.jpg</td>\n",
       "      <td>88_49733648_knit_structure</td>\n",
       "      <td>Recto</td>\n",
       "      <td>Polo</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Corta</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Cuello</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>knit_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71816</th>\n",
       "      <td>88_49735572_67076755-81_.jpg</td>\n",
       "      <td>88_49735572_knit_structure</td>\n",
       "      <td>Regular</td>\n",
       "      <td>Pico</td>\n",
       "      <td>Ligero</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Standard</td>\n",
       "      <td>Corta</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>knit_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71817</th>\n",
       "      <td>88_49713624_67092528-70_.jpg</td>\n",
       "      <td>88_49713624_knit_structure</td>\n",
       "      <td>Evase</td>\n",
       "      <td>Caja</td>\n",
       "      <td>Ligero</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Largo</td>\n",
       "      <td>Tirante Fino</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Sin cierre</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>knit_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71818</th>\n",
       "      <td>88_49726160_67076040-99_.jpg</td>\n",
       "      <td>88_49726160_knit_structure</td>\n",
       "      <td>Slim</td>\n",
       "      <td>Caja</td>\n",
       "      <td>Ligero</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Midi</td>\n",
       "      <td>Corta</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>Sin cierre</td>\n",
       "      <td>INVALID</td>\n",
       "      <td>knit_structure</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71819 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        des_filename                       test_id  \\\n",
       "0       88_49711373_67080432-99_.jpg  88_49711373_cane_height_type   \n",
       "1       88_49718802_67030656-99_.jpg  88_49718802_cane_height_type   \n",
       "2      88_49709572_67030418-01_B.jpg  88_49709572_cane_height_type   \n",
       "3       88_49722701_67066002-02_.jpg  88_49722701_cane_height_type   \n",
       "4      88_49724926_67056330-02_B.jpg  88_49724926_cane_height_type   \n",
       "...                              ...                           ...   \n",
       "71814   88_49727540_67069223-56_.jpg    88_49727540_knit_structure   \n",
       "71815   88_49733648_67017145-56_.jpg    88_49733648_knit_structure   \n",
       "71816   88_49735572_67076755-81_.jpg    88_49735572_knit_structure   \n",
       "71817   88_49713624_67092528-70_.jpg    88_49713624_knit_structure   \n",
       "71818   88_49726160_67076040-99_.jpg    88_49726160_knit_structure   \n",
       "\n",
       "      silhouette_type neck_lapel_type woven_structure knit_structure  \\\n",
       "0             INVALID         INVALID         INVALID        INVALID   \n",
       "1             INVALID         INVALID         INVALID        INVALID   \n",
       "2               Recto         Redondo          Ligero        INVALID   \n",
       "3               Evase         Redondo          Ligero        INVALID   \n",
       "4               Recto         Redondo          Ligero        INVALID   \n",
       "...               ...             ...             ...            ...   \n",
       "71814            Slim         Regular          Ligero        INVALID   \n",
       "71815           Recto            Polo         INVALID        INVALID   \n",
       "71816         Regular            Pico          Ligero        INVALID   \n",
       "71817           Evase            Caja          Ligero        INVALID   \n",
       "71818            Slim            Caja          Ligero        INVALID   \n",
       "\n",
       "      heel_shape_type length_type sleeve_length_type toecap_type waist_type  \\\n",
       "0               Plano     INVALID            INVALID     Redonda    INVALID   \n",
       "1              Bloque     INVALID            INVALID   Con punta    INVALID   \n",
       "2             INVALID    Standard              Corta     INVALID    INVALID   \n",
       "3             INVALID       Corto            INVALID     INVALID    INVALID   \n",
       "4             INVALID    Standard              Corta     INVALID    INVALID   \n",
       "...               ...         ...                ...         ...        ...   \n",
       "71814         INVALID    Standard              Larga     INVALID    INVALID   \n",
       "71815         INVALID    Standard              Corta     INVALID    INVALID   \n",
       "71816         INVALID    Standard              Corta     INVALID    INVALID   \n",
       "71817         INVALID       Largo       Tirante Fino     INVALID    INVALID   \n",
       "71818         INVALID        Midi              Corta     INVALID    INVALID   \n",
       "\n",
       "      closure_placement cane_height_type    attribute_name  \n",
       "0               INVALID             Alta  cane_height_type  \n",
       "1               INVALID          INVALID  cane_height_type  \n",
       "2               INVALID          INVALID  cane_height_type  \n",
       "3               INVALID          INVALID  cane_height_type  \n",
       "4      Cierre Delantero          INVALID  cane_height_type  \n",
       "...                 ...              ...               ...  \n",
       "71814  Cierre Delantero          INVALID    knit_structure  \n",
       "71815            Cuello          INVALID    knit_structure  \n",
       "71816           INVALID          INVALID    knit_structure  \n",
       "71817        Sin cierre          INVALID    knit_structure  \n",
       "71818        Sin cierre          INVALID    knit_structure  \n",
       "\n",
       "[71819 rows x 14 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_mapped['attribute_name'] = predictions_mapped['test_id'].apply(lambda x: \"_\".join(x.split('_')[2:]))\n",
    "\n",
    "predictions_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    'test_id': predictions_mapped['test_id'],\n",
    "    'des_value': predictions_mapped.apply(lambda row: row[row['attribute_name']], axis=1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>des_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88_49711373_cane_height_type</td>\n",
       "      <td>Alta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88_49718802_cane_height_type</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88_49709572_cane_height_type</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>88_49722701_cane_height_type</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>88_49724926_cane_height_type</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71814</th>\n",
       "      <td>88_49727540_knit_structure</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71815</th>\n",
       "      <td>88_49733648_knit_structure</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71816</th>\n",
       "      <td>88_49735572_knit_structure</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71817</th>\n",
       "      <td>88_49713624_knit_structure</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71818</th>\n",
       "      <td>88_49726160_knit_structure</td>\n",
       "      <td>INVALID</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71819 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            test_id des_value\n",
       "0      88_49711373_cane_height_type      Alta\n",
       "1      88_49718802_cane_height_type   INVALID\n",
       "2      88_49709572_cane_height_type   INVALID\n",
       "3      88_49722701_cane_height_type   INVALID\n",
       "4      88_49724926_cane_height_type   INVALID\n",
       "...                             ...       ...\n",
       "71814    88_49727540_knit_structure   INVALID\n",
       "71815    88_49733648_knit_structure   INVALID\n",
       "71816    88_49735572_knit_structure   INVALID\n",
       "71817    88_49713624_knit_structure   INVALID\n",
       "71818    88_49726160_knit_structure   INVALID\n",
       "\n",
       "[71819 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
